# ğŸ“š Projet nonâ€‘alternant â€” ModalitÃ© TEXTE

---

## ğŸš€ Vue d'ensemble
Ce dÃ©pÃ´t contient l'ensemble du code, des notebooks et des scripts permettant d'entraÃ®ner et d'Ã©valuer diffÃ©rents modÃ¨les basÃ©s sur la **modalitÃ© texte** dans le cadre du projet nonâ€‘alternant. L'objectif est d'extraire et d'exploiter des reprÃ©sentations textuelles issues de captions vidÃ©o (ou de descriptions gÃ©nÃ©rÃ©es via coNeTTe) afin d'entraÃ®ner des classifieurs neuronaux.

Plusieurs descripteurs sont Ã©tudiÃ©s :
- **SBERT embeddings**
- **Contextual embeddings** (non utilisÃ©s car trop coÃ»teux)
- **Topic Modeling**
- **Characterâ€‘level TFâ€‘IDF**
- **CLIP Text Encoder**
- **ConcatÃ©nations de descripteurs**
- **Descriptions coNeTTe**

Chaque descripteur donne lieu Ã  une initialisation, une application et un entraÃ®nement permettant de sÃ©lectionner le meilleur modÃ¨le.

---

## ğŸ—‚ Contenu du dÃ©pÃ´t
- `Yohann JEANFAIVRE - Projet non-alternant - ModalitÃ© TEXTE.ipynb` : Notebook principal pour l'ensemble des descripteurs texte.
- `Yohann JEANFAIVRE - Projet non-alternant - ModalitÃ© TEXTE avec coNeTTe.ipynb` : Version du notebook utilisant les descriptions gÃ©nÃ©rÃ©es par coNeTTe.
- `test_conette.py` : Script autonome permettant de gÃ©nÃ©rer les descriptions coNeTTe.

---

## âœ… PrÃ©requis gÃ©nÃ©raux
- Python 3.10 pour les exÃ©cutions locales
- GPU facultatif mais recommandÃ© pour SBERT / CLIP ainsi que les rÃ©seaux
- Fichiers JSON :
  - `train_videodatainfo_audio.json`
  - `val_videodatainfo_audio.json`
  - `test_videodatainfo_audio.json`

---

## ğŸ§ª 1. Notebook Â« ModalitÃ© TEXTE Â»

### ğŸ“¦ INSTALLATIONS
Ã€ exÃ©cuter uniquement lors de la premiÃ¨re utilisation du notebook.

### ğŸ“¥ IMPORTS & CHEMINS
Monter Google Drive puis spÃ©cifier :
- `chemin_json` : Emplacement des fichiers JSON des captions.
- `chemin_texte` : RÃ©pertoire contenant le notebook et oÃ¹ seront sauvegardÃ©s :
  - Les modÃ¨les `.pt`
  - Les prÃ©dictions `.csv`

---

## ğŸ”§ 2. Architecture du code
### âš™ï¸ PrÃ©paration
- Initialisation des variables.
- DÃ©finition d'une seed commune Ã  toutes les modalitÃ©s pour assurer la reproductibilitÃ©.

### ğŸ§  ModÃ¨les
Deux rÃ©seaux de neurones identiques sont dÃ©finis, seule la fonction d'activation change :
- `TextClassifierReLu`
- `TextClassifierSigmoid`

### ğŸ” Fonction clÃ© : `reseau_gridsearch`
- EntraÃ®ne un modÃ¨le avec **gridâ€‘search** sur plusieurs hyperparamÃ¨tres.
- Affiche :
  - Accuracy / Loss par epoch
  - Graphiques d'apprentissage
  - Matrice de confusion
- Sauvegarde du meilleur modÃ¨le.
- Deux modifications minimes sont nÃ©cessaires selon le descripteur (indiquÃ©es dans le code).

### ğŸ—ƒ AgrÃ©gation : `regrouperCaptionsVideo`
- Regroupe les 20 captions d'une vidÃ©o en une seule prÃ©diction via **vote majoritaire**.
- Affichage d'une matrice de confusion.

---

## ğŸ”¬ 3. Descripteurs disponibles
> âš ï¸ Chaque sousâ€‘partie est **indÃ©pendante** : n'exÃ©cuter que les blocs correspondant au descripteur souhaitÃ©.

### ğŸŸ¦ SBERT embeddings
**Initialisation :** fineâ€‘tuning lÃ©ger sur 2 epochs (long mais Ã  faire une seule fois).

**Application :** calcul des embeddings pour X_train, X_val, X_test.

### ğŸŸ§ Contextual embeddings
Non utilisÃ© car trop coÃ»teux.

### ğŸŸ© Topic Modeling
- Application du descripteur sur chaque split.
- EntraÃ®nement des modÃ¨les ReLU et Sigmoid.

### ğŸŸª Characterâ€‘level TFâ€‘IDF
**PrÃ©â€‘requis :** deux modifications dans `reseau_gridsearch` (indiquÃ©es en commentaire).

### ğŸŸ« CLIP Text Encoder
- Encoding via le textâ€‘encoder de CLIP.
- EntraÃ®nement des modÃ¨les basÃ©s sur ces embeddings.

### ğŸŸ¦ ConcatÃ©nation des deux meilleurs descripteurs
- Application des deux descripteurs sÃ©lectionnÃ©s.
- Normalisation via `l2norm`.
- EntraÃ®nement d'un modÃ¨le final combinÃ©.

---

## ğŸ“¤ 4. Export des prÃ©dictions
- GÃ©nÃ©ration d'un `.csv` contenant les **distributions de probabilitÃ©s**, utilisable en crossâ€‘modalitÃ©.
- Fonction dÃ©diÃ©e : `regrouperCaptionsVideoProba` (moyenne des distributions sur les 20 captions).
- Fichier sauvegardÃ© sous : `test_predictions_texte.csv`.

---

# ğŸ§© 5. Script local : `test_conette.py`
> âš ï¸ ExÃ©cuter **en local uniquement**.

### âœ… Installation
```
python -m venv venv_conette
venv_conette\Scripts\activate
python -m pip install --upgrade pip
pip install torch==1.13.1+cpu torchvision==0.14.1+cpu torchaudio==0.13.1+cpu --index-url https://download.pytorch.org/whl/cpu
pip install spacy==3.7.2
pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl
pip install conette==0.3.2
pip install tqdm
python test_conette.py
```

### âœ… Sortie
Le script gÃ©nÃ¨re un fichier :
- `descriptions_conette.csv`

Ã€ placer dans :
`Corpus/csv/descriptions_conette.csv`

---

# ğŸ§  6. Notebook Â« ModalitÃ© TEXTE avec coNeTTe Â»
### ğŸ“¥ PrÃ©â€‘requis
Avoir exÃ©cutÃ© `test_conette.py` et obtenu `descriptions_conette.csv`.

### ğŸ”§ Fonctionnement
Identique au notebook principal, Ã  lâ€™exception :
- des fonctions de regroupement,
- de la logique de concatÃ©nation,
- du format d'enregistrement du `.csv` final.

---

## âœ… Conclusion
Ce dÃ©pÃ´t fournit une chaÃ®ne complÃ¨te pour :
- prÃ©parer les donnÃ©es textuelles,
- calculer plusieurs types d'embeddings,
- entraÃ®ner des rÃ©seaux de neurones avec gridâ€‘search,
- exporter des prÃ©dictions compatibles crossâ€‘modalitÃ©.

Pour toute question ou amÃ©lioration, n'hÃ©sitez pas Ã  ouvrir une *issue* dans le repository ! ğŸš€

