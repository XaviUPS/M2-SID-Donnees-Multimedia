{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Donn√©es Multimedia - Projet non-alternant - Module AUDIO\n","==============\n","---"],"metadata":{"id":"Nvs6_GZGslda"}},{"cell_type":"markdown","source":["# 0.a Imports et connection google drive"],"metadata":{"id":"NQdjyBAMs6px"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CY0yz36CsA5n"},"outputs":[],"source":["import os\n","import json\n","import torch\n","import librosa\n","\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\", force_remount=True)\n","chemin_jsons : str = \"/content/drive/MyDrive/Projet non-alternant/Corpus/json/\"\n","chemin_audios : str = \"/content/drive/MyDrive/Projet non-alternant/Corpus/train_val_videos/TrainValAudio/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zvmz3BT3tU2L","executionInfo":{"status":"ok","timestamp":1761131261255,"user_tz":-120,"elapsed":22526,"user":{"displayName":"Xavi Pujol","userId":"09040852846737244226"}},"outputId":"f61b0ef4-5f6d-42b2-e353-a949ba365443"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# 0.b Fonctions de reproductibilit√©"],"metadata":{"id":"1xfYpBC7vsC4"}},{"cell_type":"code","source":["def get_device():\n","    return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","device = get_device()\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"w6OUr9_29pNp","executionInfo":{"status":"ok","timestamp":1761063797964,"user_tz":-120,"elapsed":17,"user":{"displayName":"Xavi Pujol","userId":"09040852846737244226"}},"outputId":"6a35b0e3-6181-40cf-85ed-405d1780878e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["def same_seeds(seed):\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","same_seeds(42)"],"metadata":{"id":"xVUd0RVC9ubp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"wl4qDSm9s8VF"}},{"cell_type":"code","source":["def wav_to_logmel(wav_path, sr=22050, n_mels=128, n_fft=2048, hop_length=512, duration=10):\n","    y, _ = librosa.load(wav_path, sr=sr, mono=True, duration=duration)\n","\n","    target_len = sr * duration\n","    if len(y) < target_len:\n","        y = np.pad(y, (0, target_len - len(y)), mode='constant')\n","    else:\n","        y = y[:target_len]\n","\n","    mel_spec = librosa.feature.melspectrogram(\n","        y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n","\n","    log_mel = librosa.power_to_db(mel_spec, ref=np.max)\n","\n","    log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-6)\n","\n","    return log_mel  # shape: (128, ~431) pour 10s @ 22050 Hz"],"metadata":{"id":"071EdbaB4F4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AudioCNN(nn.Module):\n","    def __init__(self, num_classes=20):\n","        super(AudioCNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((4, 4))\n","            )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(128 * 4 * 4, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"4lsx2Am97bJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AudioDataset(Dataset):\n","    def __init__(self, data, labels, normalize=True, mean=None, std=None):\n","        self.data = data\n","        self.labels = labels\n","        self.normalize = normalize\n","\n","        # Calculate mean and std if not provided\n","        if normalize and (mean is None or std is None):\n","            all_data = torch.stack([d for d in data])\n","            self.mean = all_data.mean()\n","            self.std = all_data.std()\n","        else:\n","            self.mean = mean\n","            self.std = std\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sample = self.data[idx]\n","        label = self.labels[idx]\n","\n","        # Normalize\n","        if self.normalize:\n","            sample = (sample - self.mean) / (self.std + 1e-8)\n"],"metadata":{"id":"uC5X_XU5Gcdy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AudioDataset(Dataset):\n","    def __init__(self, csv_path, audio_dir):\n","        self.df = pd.read_csv(csv_path)\n","        self.audio_dir = audio_dir\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        video_id = row[\"video_id\"]\n","        label = int(row[\"label\"])\n","\n","        audio_path = os.path.join(self.audio_dir, f\"{video_id}.wav\")\n","        logmel = wav_to_logmel(audio_path)\n","        logmel = torch.tensor(logmel).unsqueeze(0).float()\n","        label = torch.tensor(label, dtype=torch.long)\n","\n","        return logmel, label\n","\n","# ----------------------------\n","# Cr√©ation des DataLoaders\n","# ----------------------------\n","def get_dataloaders(\n","    train_csv,\n","    val_csv,\n","    audio_dir,\n","    batch_size=16,\n","    num_workers=2\n","):\n","    train_dataset = AudioDatasetFromCSV(train_csv, audio_dir)\n","    val_dataset = AudioDatasetFromCSV(val_csv, audio_dir)\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=num_workers,\n","        pin_memory=True\n","    )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=num_workers,\n","        pin_memory=True\n","    )\n","\n","    print(f\"‚úÖ Train set: {len(train_dataset)} √©chantillons\")\n","    print(f\"‚úÖ Val set: {len(val_dataset)} √©chantillons\")\n","    return train_loader, val_loader"],"metadata":{"id":"zskiaC5El2P3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MSRVTAudioDataset(Dataset):\n","    def __init__(self, json_path, audio_dir, transform=None):\n","        with open(json_path, 'r') as f:\n","            data = json.load(f)\n","        self.videos = data['videos']\n","        self.audio_dir = audio_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.videos)\n","\n","    def __getitem__(self, idx):\n","        vid = self.videos[idx]\n","        video_id = vid['video_id']\n","        label = vid['category']\n","        audio_path = os.path.join(self.audio_dir, f\"{video_id}.wav\")\n","\n","        if not os.path.exists(audio_path):\n","            raise FileNotFoundError(f\"Audio manquant : {audio_path}\")\n","\n","        logmel = wav_to_logmel(audio_path)  # (128, T)\n","        logmel = torch.tensor(logmel).unsqueeze(0)  # (1, 128, T)\n","\n","        return logmel.float(), label"],"metadata":{"id":"0FpPG7nr7H-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, learning_rate,\n","                num_epochs=20, patience=5, save_path=\"best_model.pth\"):\n","\n","    device = get_device()\n","    model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    best_val_loss = float('inf')\n","    epochs_no_improve = 0\n","    best_epoch = 0\n","\n","    for epoch in range(num_epochs):\n","        # ---------- Entra√Ænement ----------\n","        model.train()\n","        train_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        for x, y in train_loader:\n","            x, y = x.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            out = model(x)\n","            loss = criterion(out, y)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            _, predicted = torch.max(out.data, 1)\n","            total_train += y.size(0)\n","            correct_train += (predicted == y).sum().item()\n","\n","        train_acc = 100 * correct_train / total_train\n","        avg_train_loss = train_loss / len(train_loader)\n","\n","        # ---------- Validation ----------\n","        model.eval()\n","        val_loss = 0.0\n","        correct_val = 0\n","        total_val = 0\n","\n","        with torch.no_grad():\n","            for x, y in val_loader:\n","                x, y = x.to(device), y.to(device)\n","                out = model(x)\n","                loss = criterion(out, y)\n","                val_loss += loss.item()\n","                _, predicted = torch.max(out.data, 1)\n","                total_val += y.size(0)\n","                correct_val += (predicted == y).sum().item()\n","\n","        val_acc = 100 * correct_val / total_val\n","        avg_val_loss = val_loss / len(val_loader)\n","\n","        # ---------- Affichage ----------\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n","              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n","              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n","\n","        # ---------- Early Stopping ----------\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            epochs_no_improve = 0\n","            best_epoch = epoch\n","            torch.save(model.state_dict(), save_path)\n","            print(f\"  ‚Üí Nouveau meilleur mod√®le sauvegard√© √† l'√©poque {epoch+1} !\")\n","        else:\n","            epochs_no_improve += 1\n","            if epochs_no_improve >= patience:\n","                print(f\"\\nüõë ¬°Early stopping d√©clench√© apr√®s {epoch+1} √©poques.\")\n","                print(f\"Meilleur mod√®le √† l'√©poque {best_epoch+1} (val_loss = {best_val_loss:.4f})\")\n","                break\n","\n","    # Recharger le meilleur mod√®le\n","    model.load_state_dict(torch.load(save_path, map_location=device))\n","    print(f\"\\n‚úÖ Entra√Ænement termin√©. Meilleur mod√®le charg√© depuis {save_path}.\")\n","    return model"],"metadata":{"id":"8Rpmictj94ak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_json = \"/content/drive/MyDrive/Projet non-alternant/Corpus/json/train_videodatainfo_audio.json\"\n","val_json = \"/content/drive/MyDrive/Projet non-alternant/Corpus/json/val_videodatainfo_audio.json\"\n","audio_dir = \"/content/drive/MyDrive/Projet non-alternant/Corpus/train_val_videos/TrainValAudio\""],"metadata":{"id":"NYFFSGiX778u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_train_dataset = MSRVTAudioDataset(train_json, audio_dir)\n","full_val_dataset = MSRVTAudioDataset(val_json, audio_dir)"],"metadata":{"id":"LzbgXKxoHFYJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N = 1000\n","n = 200\n","train_dataset = torch.utils.data.Subset(full_train_dataset, indices=list(range(min(N, len(full_train_dataset)))))\n","val_dataset = torch.utils.data.Subset(full_val_dataset, indices=list(range(min(n, len(full_val_dataset)))))\n","\n","print(f\"Train subset size: {len(train_dataset)}\")\n","print(f\"Val subset size: {len(val_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TK4sl3y3HHaO","executionInfo":{"status":"ok","timestamp":1761056761662,"user_tz":-120,"elapsed":167,"user":{"displayName":"Xavi Pujol","userId":"09040852846737244226"}},"outputId":"abca126b-13a9-4c7f-efff-24fd066c7d8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train subset size: 1000\n","Val subset size: 200\n"]}]},{"cell_type":"code","source":["# Datasets\n","train_dataset = MSRVTAudioDataset(train_json, audio_dir)\n","val_dataset = MSRVTAudioDataset(val_json, audio_dir)"],"metadata":{"id":"89mMFiRO8Yzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)"],"metadata":{"id":"MAuyEH6v8az2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mod√®le\n","model = AudioCNN(num_classes=20)\n","model.to(get_device())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StSBQBZt8cmJ","executionInfo":{"status":"ok","timestamp":1761056769148,"user_tz":-120,"elapsed":148,"user":{"displayName":"Xavi Pujol","userId":"09040852846737244226"}},"outputId":"9652e026-f441-4fe7-c2dc-4d109f41cde5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AudioCNN(\n","  (features): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU()\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU()\n","    (11): AdaptiveAvgPool2d(output_size=(4, 4))\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=2048, out_features=512, bias=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=512, out_features=20, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["model = train_model(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    learning_rate=0.01,\n","    num_epochs=30,\n","    patience=5,\n","    save_path=\"/content/drive/MyDrive/Projet non-alternant/Audio/best_audio_cnn.pth\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"dYYhZW8x-ZNX","executionInfo":{"status":"error","timestamp":1761056860473,"user_tz":-120,"elapsed":59729,"user":{"displayName":"Xavi Pujol","userId":"09040852846737244226"}},"outputId":"f28fa770-eaa9-43a6-a33b-2fa540e15adb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3978843677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = train_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1547216447.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, learning_rate, num_epochs, patience, save_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtotal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3613782915.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Audio manquant : {audio_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlogmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav_to_logmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (128, T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlogmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (1, 128, T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-50150056.py\u001b[0m in \u001b[0;36mwav_to_logmel\u001b[0;34m(wav_path, sr, n_mels, n_fft, hop_length, duration)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwav_to_logmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Otherwise try soundfile first, and then fall back if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFileRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Check one batch\n","for batch_data, batch_labels in train_loader:\n","    print(f\"Batch data shape: {batch_data.shape}\")  # e.g., [32, 1, 128, 128]\n","    print(f\"Batch labels shape: {batch_labels.shape}\")  # e.g., [32]\n","    print(f\"Data range: [{batch_data.min():.2f}, {batch_data.max():.2f}]\")\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJP2JaDhDSc4","executionInfo":{"status":"ok","timestamp":1761054910723,"user_tz":-120,"elapsed":7788,"user":{"displayName":"Xavi Pujol","userId":"09040852846737244226"}},"outputId":"b75b79fb-01a4-4574-ad92-f43dff24a347"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch data shape: torch.Size([16, 1, 128, 431])\n","Batch labels shape: torch.Size([16])\n","Data range: [-4.65, 4.20]\n"]}]}]}