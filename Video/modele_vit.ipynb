{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJ0yPdqoST43","executionInfo":{"status":"ok","timestamp":1762174320464,"user_tz":-60,"elapsed":199787,"user":{"displayName":"Q Bwj Bwbw","userId":"12243021587343755842"}},"outputId":"12d1633e-ac26-44fb-acd3-01751ecc4f2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# ============================================================\n","# ‚öôÔ∏è INSTALLATION ET IMPORTS\n","# ============================================================\n","!pip install torch torchvision tqdm -q\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms, models\n","from tqdm import tqdm\n","from torch.cuda.amp import autocast, GradScaler\n","import cv2, numpy as np, pickle\n","from google.colab import drive\n","\n","# ============================================================\n","# 1Ô∏è‚É£ MONTAGE DU DRIVE\n","# ============================================================\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# ============================================================\n","# 2Ô∏è‚É£ DATASET PICKLE (inchang√©)\n","# ============================================================\n","class PKLVideoDataset(Dataset):\n","    def __init__(self, x_files, y_files, transform=None, target_frames=16):\n","        self.videos, self.labels = [], []\n","        self.transform = transform\n","        self.target_frames = target_frames\n","        for xf, yf in zip(x_files, y_files):\n","            with open(xf, \"rb\") as f: self.videos.extend(pickle.load(f))\n","            with open(yf, \"rb\") as f: self.labels.extend(pickle.load(f))\n","\n","    def __len__(self): return len(self.videos)\n","\n","    def __getitem__(self, idx):\n","        video, label = self.videos[idx], self.labels[idx]\n","        frames = [cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in video]\n","\n","        # Normaliser la longueur des vid√©os\n","        if len(frames) < self.target_frames:\n","            repeat = int(np.ceil(self.target_frames / len(frames)))\n","            frames = (frames * repeat)[:self.target_frames]\n","        else:\n","            frames = frames[:self.target_frames]\n","\n","        if self.transform:\n","            frames = [self.transform(f) for f in frames]\n","        video_tensor = torch.stack(frames, dim=1)  # (C, T, H, W)\n","        return video_tensor, torch.tensor(label, dtype=torch.long)\n","\n","# ============================================================\n","# 3Ô∏è‚É£ TRANSFORMATIONS (sp√©cifique √† MViTv2)\n","# ============================================================\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)),  # entr√©e attendue 224x224\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n","                         std=[0.22803, 0.22145, 0.216989]),\n","])\n","\n","# ============================================================\n","# 4Ô∏è‚É£ CHEMINS DES DONN√âES\n","# ============================================================\n","x_files = [\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_train1_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_train2_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_train3_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_train4_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_train5_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_train6_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_train8_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_train7_small3.pkl\",\n","\n","]\n","y_files = [\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_train1.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_train2.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_train3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_train4.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_train5.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_train6.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_train8.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_train7.pkl\",\n","]\n","# Fichiers de validation\n","x_val_files = [\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_val1_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_val2_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_val3_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_val4_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_val5_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_val6_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_val8_small3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/X_val7_small3.pkl\",\n","\n","]\n","y_val_files = [\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_val1.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_val2.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_val3.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_val4.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_val5.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_val6.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_val8.pkl\",\n","    \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/ensemble_non_hasard/y_val7.pkl\",\n","\n","]\n","# ============================================================\n","# 5Ô∏è‚É£ DATALOADERS\n","# ============================================================\n","train_dataset = PKLVideoDataset(x_files, y_files, transform=transform)\n","val_dataset = PKLVideoDataset(x_val_files, y_val_files, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n","\n","# ============================================================\n","# 6Ô∏è‚É£ MOD√àLE MViTv2\n","# ============================================================\n","class MViTv2Custom(nn.Module):\n","    def __init__(self, num_classes=20, pretrained=True, dropout_p=0.3):\n","        super().__init__()\n","        weights = models.video.MViT_V2_S_Weights.KINETICS400_V1 if pretrained else None\n","        self.backbone = models.video.mvit_v2_s(weights=weights)\n","        in_features = self.backbone.head[1].in_features\n","        self.backbone.head[1] = nn.Sequential(\n","            nn.Linear(in_features, 512),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout_p),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.backbone(x)\n","\n"]},{"cell_type":"code","source":["def same_seeds(seed):\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","same_seeds(42)"],"metadata":{"id":"suuC1EaVJIDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.cuda.amp import autocast, GradScaler\n","from tqdm import tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MViTv2Custom(num_classes=20).to(device)\n","\n","optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n","criterion = nn.CrossEntropyLoss()\n","scaler = GradScaler()\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n","\n","num_epoch = 10\n","best_acc = 0.0\n","model_path = \"/content/drive/MyDrive/Projet non-alternant/Vid√©o/best_mvitvnop.pth\"\n","\n","for epoch in range(num_epoch):\n","    model.train()\n","    total_loss, correct, total = 0.0, 0, 0\n","    for videos, labels in tqdm(train_loader, desc=f\"√âpoque {epoch+1}/{num_epoch}\"):\n","        videos, labels = videos.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","\n","\n","\n","        with autocast():\n","            outputs = model(videos)\n","            loss = criterion(outputs, labels)\n","\n","        # üîß Backpropagation avec GradScaler\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        total_loss += loss.item()\n","        correct += (outputs.argmax(1) == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_acc = correct / total\n","    train_loss = total_loss / len(train_loader)\n","\n","    # Validation\n","    model.eval()\n","    val_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for videos, labels in val_loader:\n","            videos, labels = videos.to(device), labels.to(device)\n","            with autocast():\n","                outputs = model(videos)\n","                loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            val_correct += (outputs.argmax(1) == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_acc = val_correct / val_total\n","    val_loss /= len(val_loader)\n","    scheduler.step()\n","\n","    print(f\"üìä √âpoque [{epoch+1}/{num_epoch}] \"\n","          f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | \"\n","          f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n","\n","    if val_acc > best_acc:\n","        best_acc = val_acc\n","        torch.save(model.state_dict(), model_path)\n","        print(f\"üíæ Nouveau meilleur mod√®le sauvegard√© (Val Acc: {best_acc:.4f})\")\n","\n","print(\"‚úÖ Entra√Ænement termin√©. Meilleure pr√©cision validation :\", best_acc)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxkRG1jvcEjc","outputId":"c7df1c61-d0c0-455d-c8fe-aa5c8a1fcc58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/mvit_v2_s-ae3be167.pth\" to /root/.cache/torch/hub/checkpoints/mvit_v2_s-ae3be167.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 132M/132M [00:00<00:00, 142MB/s]\n","/tmp/ipython-input-1814043583.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","√âpoque 1/10:   0%|          | 0/1489 [00:00<?, ?it/s]/tmp/ipython-input-1814043583.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n","√âpoque 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1489/1489 [17:07<00:00,  1.45it/s]\n","/tmp/ipython-input-1814043583.py:50: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n"]},{"output_type":"stream","name":"stdout","text":["üìä √âpoque [1/10] Train Acc: 0.2986 | Val Acc: 0.4221 | Train Loss: 2.3967 | Val Loss: 2.0438\n","üíæ Nouveau meilleur mod√®le sauvegard√© (Val Acc: 0.4221)\n"]},{"output_type":"stream","name":"stderr","text":["√âpoque 2/10:   8%|‚ñä         | 119/1489 [01:23<15:52,  1.44it/s]"]}]}]}